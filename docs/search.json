[
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "From number names to language families\n\n\n21 min\n\n\nWith numbers 1-10, just 10 words, can we classify languages into known language families?\n\n\n\nMonday, April 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn sorting numbers alphabetically in different languages and other absurdities\n\n\n11 min\n\n\nFirst contact with numbers 1-10 across +5000 languages and curious insights\n\n\n\nSunday, March 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is this for?\n\n\n3 min\n\n\nA brief explanation\n\n\n\nTuesday, January 2, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/LangNums/LangFacts/LangFacts.html",
    "href": "blog/posts/LangNums/LangFacts/LangFacts.html",
    "title": "On sorting numbers alphabetically in different languages and other absurdities",
    "section": "",
    "text": "Have you ever wondered if we could compare languages simply by examining their first N number names, sorted alphabetically? It may seem absurd but intriguing at the same time. This was the question that came to my mind about a year ago.\nInitially, I wanted to tackle this question in one post. However, as I explored the data further, I realized there was much more to uncover than I initially thought. Therefore, I’ve decided to split our journey into two separate posts.\nThis post will serve as an introduction. We’ll find out some interesting and fun facts from our first look into the data. But wait, there’s more! The real fun is coming up in the next post: From number names to language families, which promises to be even more exciting and interesting (and colorful).\nAs an added bonus, I’ve created a Shiny app where you can visualize +3800 languages in an interactive 3D plot. I personally think it’s awesome. Even though I called it a bonus, it’s so cool that it could be the main result of this project. Check out the Shiny app here: https://olafmeneses.shinyapps.io/LangNet\nI hope you find this initial exploration as fascinating as I did, where you’ll discover some languages you probably didn’t even know existed and some odd facts about them!"
  },
  {
    "objectID": "blog/posts/LangNums/LangFacts/LangFacts.html#first-becomes-last",
    "href": "blog/posts/LangNums/LangFacts/LangFacts.html#first-becomes-last",
    "title": "On sorting numbers alphabetically in different languages and other absurdities",
    "section": "First becomes last",
    "text": "First becomes last\nWe start by identifying which languages have the number 1 in the last position. We do it first for a subset of languages which have +1 million speakers (178 languages).\n\n\n\n\n\n\nBelow you can find the extended version for the set of 3893 languages.\n\n\n\n\n\n\nCurious fact: the percentage of languages exhibiting this phenomenon remains consistent across datasets of different sizes (first set has 178 languages and the other one +3800).\n\n\n\n\n\n\n\nDataset size\n% of languages with phenomenon\n\n\n\n\n178\n1.44%\n\n\n3893\n1.35%"
  },
  {
    "objectID": "blog/posts/LangNums/LangFacts/LangFacts.html#perfect-alphabetical-sorting",
    "href": "blog/posts/LangNums/LangFacts/LangFacts.html#perfect-alphabetical-sorting",
    "title": "On sorting numbers alphabetically in different languages and other absurdities",
    "section": "Perfect alphabetical sorting",
    "text": "Perfect alphabetical sorting\nWhich languages have their numbers perfectly sorted when the number names are sorted alphabetically?\n\n\n\n\n\n\nLooking at the results, we can see that the first language is Afro-Asiatic numerals, where sorting alphabetically doesn’t make any sense (they are characters used to represent the numbers).\nRegarding the rest of the languages, it’s noteworthy that most of them belong to the family of Constructed languages. Let’s take a look at Langue nouvelle:\n\n\n\n\n\n\n\nLangue nouvelle (French for ‘new language’) is a grammatical sketch for a proposed artificial international auxiliary language presented in 1765 by Joachim Faiguet de Villeneuve, a French economist, in the ninth volume of Diderot’s encyclopedia. […] Each numeral starts with a different consonant, and are in alphabet order.\n(“Langue Nouvelle - Wikipedia”)\n\nThis is interesting. Considering that the alphabet itself is a product of human invention, it becomes improbable for the initial N numbers of any language (which use an alphabet) to be arranged alphabetically by chance. Out of +3800 languages only 8 have their first 10 numbers sorted in alphabetical order perfectly. From those 8, 75% of them are constructed languages.\nTherefore, we can conclude that this feature arises from deliberate design rather than occurring by chance or natural evolution. I was hoping that more (non-artificial) languages would have this feature, but it’s rarer than I thought."
  },
  {
    "objectID": "blog/posts/LangNums/LangFacts/LangFacts.html#which-is-the-language-with-most-characters-for-all-numerals",
    "href": "blog/posts/LangNums/LangFacts/LangFacts.html#which-is-the-language-with-most-characters-for-all-numerals",
    "title": "On sorting numbers alphabetically in different languages and other absurdities",
    "section": "Which is the language with most characters for all numerals?",
    "text": "Which is the language with most characters for all numerals?\nWhoa! What’s happening here? 241 characters to say only the numbers 1 to 10?\n\n\n\n\n\n\nActually, you can take a look at what’s happening with the Sissano language. You can see that it’s repeating the previous numbers. We can identify a structure like this one (where we replace the names of the numbers between brackets):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\npontanen\nentin\n[2] e [1]\n[2] ke [2]\n[4] ke [1]\n[4] ke [2]\n[6] [1]\n[6] ke [2]\n[8] ke [1]\n[8] ke [2]\n\n\n\nSissano only has number names for 1, 2 and a few (Parker 2007). The remaining numbers are formed by combining the names of 1 and 2. It’s using a base-2 (or binary) numeral system."
  },
  {
    "objectID": "blog/posts/LangNums/LangFacts/LangFacts.html#and-with-the-least-number-of-characters",
    "href": "blog/posts/LangNums/LangFacts/LangFacts.html#and-with-the-least-number-of-characters",
    "title": "On sorting numbers alphabetically in different languages and other absurdities",
    "section": "And with the least number of characters?",
    "text": "And with the least number of characters?\nExceptuating (again) the languages where we have the numerals or the written form of the numbers, the majority of them are constructed languages. Seems like there are some languages which assign the vocal letters {a,e,i,o,u} to the numbers following some order. I’ve been trying to find some information about this but haven’t found anything interesting. The only thing I know is that Zahlensprache means Number language."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello!",
    "section": "",
    "text": "Hello!\nI’m Olaf, currently a third-year Data Science student at the University of Valencia. I have a strong foundation in key data science disciplines, a proven track record of academic excellence, and a passion for data-driven insights and innovation.\n\nAcademic Excellence\nThroughout my academic journey, I have consistently demonstrated my dedication to excellence. Only in the last two years, I have earned a total of 20 distinctions with Honors in various subjects, including: Statistical Inference, Databases, Data Processing, Data Visualization…\n\n\nAwards and Recognition\n\nFirst prize in the II Valencia SDG Data Visualization Contest (Sep. 2022), with the project Ruzafapp.\nSecond prize in the Valencia SDG Data Visualization Contest (Sep. 2023), with the project VLC TrànsitAire, where I collaborated with a team of five members.\nTop 1% of University Entrance Exam (PAU) scores at the University of Valencia, out of nearly 7000 students.\n\n\n\nNot everything is Data Science\nBeyond data science, I have a diverse range of passions, including exploring second-hand bookstores, finding inspiration in poetry and literature, and embarking on urban (and not so urban) adventures on foot."
  },
  {
    "objectID": "blog/posts/init/init.html",
    "href": "blog/posts/init/init.html",
    "title": "What is this for?",
    "section": "",
    "text": "This was a triumph!\nI’m making a blog here.\n\n\n\nWhat is this blog for?\nThis is a personal blog. Personal means I have the freedom to write about anything that interests me and, more importantly, to do so when I like. Don’t expect regular updates – this won’t be a daily, weekly, or even monthly affair. This is not a newsletter. I imagine this as a shelf of personal experiences. After I finish something I’ve worked on and consider meaningful, I place it on the shelf. A public library of my personal experiences (related to data science).\nYou can also consider it as an observer’s notebook. I believe I’m a very observant person. I tend to notice details that escape the attention of the vast majority. Here, you will find the thought process of some projects I’ve worked on, small projects, ideas, thoughts… or anything that catches my attention.\nHaving explained that, the question that naturally arises is…\n\n\nWho am I talking to?\nSince I make this blog public on the Internet, it’s obvious that anyone can read it. But that doesn’t mean my target audience is anyone. Why would anyone care about some data science projects?\nI don’t really know how you got here. Maybe you’re working on a task that is similar to something I’ve done. You may end up saving some time, you may come up with a different solution than the one you had in mind… or maybe you just want to learn about the projects I’ve worked on. Either way, I hope you find great value in the mistakes and successes I’ve had so far. I believe there’s always something to learn or discover.\nI’m also talking to my future self. As I said before, I want to think about this blog as a notebook or repository of my observations during my journey as a data scientist. But I could do this without making it public, so let’s ignore this case.\n\n\nThe End of the Beginning\nThe other sections begin with a question. This one doesn’t.\nLife constantly asks you questions (many people believe that they are the ones asking the questions, although it’s the opposite). When life comes to an end, it stops asking, since you cannot answer. When life comes to an end, you must quote something and remain silent, leaving the echo alive:\n\nThink of all the things we learned for the people who are still alive."
  },
  {
    "objectID": "blog/posts/LangNums/LangClust/LangClust.html",
    "href": "blog/posts/LangNums/LangClust/LangClust.html",
    "title": "From number names to language families",
    "section": "",
    "text": "This post is a continuation of a previous post: On sorting numbers alphabetically in different languages and other absurdities, where we made a little exploration of number names from 1 to 10 across +5000 languages and learnt some curiosities along the way. Nonetheless, you don’t need to read it to understand this one. They’re somewhat independent.\nGiven the title and description of the post, you can imagine what we will see today. The idea is to try some classification, clustering and dimensionality reduction techniques to see what these 10 words can tell us about different language families.\nAs I mentioned in the previous post, I’ve also created a Shiny app where you can visualize +3800 languages in an interactive 3D plot. I think it’s pretty cool. I highly recommend checking it out: https://olafmeneses.shinyapps.io/LangNet\nBefore we start getting into the matter, let’s take a look at the data. For each language, we have the following information:\nData is taken from (Rosenfelder). For example, in the case of English, we would have:\nWe can have a look at all the languages in the following table, where we show the language, its family and the names of its numbers."
  },
  {
    "objectID": "blog/posts/LangNums/LangClust/LangClust.html#which-distance-is-better",
    "href": "blog/posts/LangNums/LangClust/LangClust.html#which-distance-is-better",
    "title": "From number names to language families",
    "section": "Which distance is better?",
    "text": "Which distance is better?\nMy idea (initially and because of the previous post) was to compare languages by looking at the positions of their numbers sorted alphabetically. I didn’t have any hope that it would be great. It wasn’t great. At all. This distance is somewhat random and doesn’t retain relevant information. However, I think that stupid ideas sometimes (and only sometimes) lead you to interesting places.\nAfter the initial failure, I tried with a well-known distance for strings: Levenshtein distance.\nThe Levenshtein distance counts the minimum number of single-character edits (insertions, deletions, or substitutions) needed to change one string into the other. So, the smaller the Levenshtein distance between two strings, the more similar they are.\nWe will now see an example of why we should make some modifications to define a new distance. If you have the strings “hello” and “hello”, the Levenshtein distance is 0. That makes sense. But here’s the problem:\n\n\n\n\n\n\n\n\nString 1\nString 2\nLevenshtein Distance\n\n\n\n\nhello\nhellozzzzz\n5\n\n\nhello\nazxyp\n5\n\n\n\nAlthough both have the same Levenshtein distance of 5, would you say that both strings are at the same distance (equally similar/dissimilar)? We can address this by normalizing the distance.\nTo do this, we divide the distance calculated by the maximum length of the strings s1 and s2 being compared (\\(max(length(\\text{s1}),\\,length(\\text{s1}))\\), where length is the number of characters of each string). The minimum distance is 0, while the maximum distance is set at 1:\n\n\n\n\n\n\n\n\nString 1\nString 2\nNormalized Levenshtein Distance\n\n\n\n\nhello\nhellozzzzz\n0.5\n\n\nhello\nazxyp\n1\n\n\n\nThis way, we can compare distances between strings of different lengths more fairly.\nWe will compare different distance functions (the one based on alphabetically ordering, DL [Damerau-Levenshtein], Levenshtein and OSA [Optimal String Alignment]). These last three are string distance functions and variations of Levenshtein’s idea. We will also compare the unmodified and normalized versions.\nAs we already said, we will calculate the accuracy with the k-NN. First, we will see for which value of k we get the higher mean accuracy. As we can see in the table below, the best option is k=1.\n\n\n\n\n\n\nFor this value of k, we can see which are the distances with higher accuracy with the next plot. The normalized versions are slightly better than the unmodified ones. The accuracy with the distance based on the alphabetic sorting is awful.\n\n\n\n\n\n\n\n\n\nFinally, we show which is the mean accuracy for each distance.\n\n\n\n\n\n\n\nBest distance\nThe distance we will use from now on is the normalized version of Damerau-Levenshtein. The accuracy score for the different families/subfamilies levels can be found in the next table. We have to take into account that with this method we cannot classify correctly some languages because we only have one sample from that family (for example, Basque, a language isolate). Because of this, correct classification can be achieved for only 3557 out of the 3567 languages in this set.\n\n\n\n\n\n\n\n\nWhy do we get so good results?\nWhen I first saw these accuracy results, I was a little bit surprised. I expected an accuracy for the first-level family ranged between 0.6-0.8. Instead, what we got here is that we correctly classified 3273 out of 3567 languages (91.76%).\nI had some intuition on why it worked so well. My initial curiosity prompted me to investigate further. I stumbled upon (Calude 2021), which sheds light on the matter:\n\nLexical replacement rates vary enormously among words and among languages. In words that linguists believe to be the least rapidly changing within a given language, namely words that designate basic vocabulary terms, like foot, green, man, dirty, husband, wife, mother, and including numbers one through to five—a collection of words termed the Swadesh List (named after Morris Swadesh, who formulated various such lists)—rates of lexical replacement can still vary between word-forms as much as 100-fold [7, p. 8]. But number words stand out as being among the most conservatively preserved word-forms even in such basic vocabulary lists [7]. Remarkably, in the Indo-European language family, a single cognate set can be traced throughout its entire history, indicating astonishing agreement across speakers and time [7]. Put another way, speakers of Indo-European languages have preserved ancestral forms for low-limit numbers with extreme fidelity over thousands of years of language change.\n\nThis led me to the referenced article [7] (Pagel and Meade 2017), which I highly recommend reading. In it, the authors propose three hypotheses to explain the unusual conservation of number names (I have consistently used the expression number names but the authors refer to them as number words):\n\n\nEvolutionarily conserved brain regions associated with numerosity (somehow) influence the learning and use of linguistic-symbolic number words\nNumber words are unambiguous in their meanings and therefore less likely to admit alternatives\nNumber words occupy a region of the phonetic space that is relatively full\n\n\nWhile all three hypotheses are valid, the second one seems the most reasonable to me. An explanation I liked from (Calude 2021):\n\nAll the evidence thus shows that low-limit numbers in languages that have productive higher numbers behave in a stable, uniform manner across large time scales and varied speaker populations. The question is, why are these low-limit numbers so resistant to change? A highly plausible hypothesis comes from the lack of variation in the system [7]. Owing to their concrete and specific meanings [32], there is less room for near-synonyms to develop and even when they do, these remain context-restricted and low in frequency (compare twelve with dozen), leading to fixation. This is precisely what was observed of the LAMSAS and LAGS American English data [31]. The findings also support a more general law of semantic change, the Law of Innovation, proposed by Hamilton et al. [33], which contends that polysemous words tend to change their meanings faster, showing Social Conformist Bias effects in language change. Yet, it is still unclear what keeps the variation among number words so low; why do we entertain various words for parlour but only one for three?\n\nThat final question is key. Words describe what we observe/imagine (a reality). The word house could be used to describe thousands of realities (from a small cabin in the woods to a skyscraper in the city). The word house describes a highly variable concept. In order to reduce ambiguity, we need synonyms that fit better the reality we are trying to describe (like mansion or apartment). However, number names describe the quantitative dimension with a very high degree of certainty. This means that, in the case of numbers (when trying to describe quantities), we rarely need a synonym.\nI must say, though, that this extends beyond numbers. Consider the names of days and months, which are human-created conventions for organizing and navigating time. The use of these terms facilitates precise communication. However, they are not necessary, nor innate. Humans can live without precise counting or timekeeping. Another question arises: How far could a society progress without them? We’ll leave that for another day.\nApologies for this boring dissertation; let’s get back to our problem.\nIf numbers 1-10 evolve steadily, it seems feasible to find a neighbor within the same language family using the Levenshtein distance (or a similar one). As we obtain more samples from a particular language family, it becomes more probable that the closest neighbor of a given language belongs to the same family.\n\n\nSome insights into the misclassifcation\nIn the following table we can see ten of the families and their classification accuracy, sorted by the number of languages. Seems like it worked for almost all families. But why do we have an abrupt difference with Indo-Pacific? While for some families like Austronesian or Indo-European we achieved almost a 100% accuracy, for this family we couldn’t even achieve 60%.\n\n\n\n\n\n\nAfter reading the Wikipedia article about Indo-Pacific languages, it seems like this is a hypothetical language family that is not accepted by specialists. We can see some of the incorrect predictions for the Indo-Pacific family in the table below. Most of the closest neighbors identified are from the Austronesian language family. Even though it’s wrong based on the correct classification, it makes more sense:"
  },
  {
    "objectID": "blog/posts/LangNums/LangClust/LangClust.html#dimensionality-reduction",
    "href": "blog/posts/LangNums/LangClust/LangClust.html#dimensionality-reduction",
    "title": "From number names to language families",
    "section": "Dimensionality reduction",
    "text": "Dimensionality reduction\nIn order to visualize the different clusters corresponding to the language families, we will use two dimensionality reduction techniques: MDS and tSNE. We will not use the set of +3000 languages, but a smaller one of (178) languages which have +1 million speakers.\nI will not explain how MDS or tSNE (Maaten and Hinton 2008) work (for that, I recommend this and this), since it’s not the main goal of this post.\n\nMDS\nUsing MDS, it appears feasible to distinguish families with a larger number of languages, such as Indo-European and Niger-Congo, while the remaining languages are clustered together. It’s important to note that in MDS, the x, y, and z axes lack an interpretable meaning.\nNote: You can click on any image to make it bigger.\n\n\n\n\n\n\n\n\n\nHere’s a 3D plot that you can interact with. You can observe that adding a third dimension helps to separate some clusters like Sino-Tibetan or Tai (yellow/orange colors). Still, there are many points clustered in the center.\n\n\n\n\n\n\n\n\ntSNE\nWith tSNE, it seems that we can capture both the local and global structure of the data. The different language families are more apart from each other and, moreover, language families that are somewhat related (Tai and Sino-Tibetan) are close to each other. As in MDS, the x, y, and z axes do not have an interpretable meaning.\n\n\n\n\n\n\n\n\n\nIn the 3D plot, it becomes easier to assess how well tSNE performed."
  },
  {
    "objectID": "blog/posts/LangNums/LangClust/LangClust.html#k-nearest-neighbors-graph",
    "href": "blog/posts/LangNums/LangClust/LangClust.html#k-nearest-neighbors-graph",
    "title": "From number names to language families",
    "section": "k-Nearest Neighbors graph",
    "text": "k-Nearest Neighbors graph\nIf you prefer a simpler interface, you can explore a k-NN graph here. You have selectors to highlight family groups or languages and zoom in to observe closely related languages. We are using the same layout of points from tSNE but we have added some jitter to the points to prevent overlap with the language name labels.\nI highly recommend interacting with it: click on any language, and it will highlight its neighbors. As in previous examples, we use k=1."
  },
  {
    "objectID": "blog/posts/LangNums/LangClust/LangClust.html#hierarchical-clustering",
    "href": "blog/posts/LangNums/LangClust/LangClust.html#hierarchical-clustering",
    "title": "From number names to language families",
    "section": "Hierarchical clustering",
    "text": "Hierarchical clustering\nWe carried out a hierarchical cluster analysis using the McQuitty agglomeration (linkage) method to explore the linguistic relationships within the Indo-European language family. The decision to focus on Indo-European languages was intentional for two reasons. Firstly, the Indo-European language family stands out as one of the most thoroughly researched and widely recognized language families in linguistics; therefore, we have greater certainty about the established subfamilies. Secondly, by selecting a reduced subset, we simplify the visualization.\nNote: Every dendrogram will be preceded by a legend, providing clarity on the color scheme used to represent different language subfamilies.\nFor this first dendrogram, we color-coded each language based on its first subfamily. By visualizing the dendrogram in this manner, we gain insights into the higher-level relationships among language subfamilies, such as Germanic, Romance, Slavic, and others.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this second dendrogram, we opted to color-code each language according to its deepest subfamily possible within the Indo-European family tree. For instance, if two languages belong to the same subfamily but diverge at deeper levels, they will be represented with distinct colors in the dendrogram. This approach tries to visualize with finer detail how Indo-European languages are connected and how they’ve evolved. Although the dendrogram is not perfect, I would say it is quite good and approximates the established subfamilies."
  },
  {
    "objectID": "projects/LangNet.html",
    "href": "projects/LangNet.html",
    "title": "LangNet",
    "section": "",
    "text": "Link (English): https://olafmeneses.shinyapps.io/LangNet Post under construction…"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "This post is still under construction. Click on the images to navigate to the respective project links."
  },
  {
    "objectID": "projects/DelFuegoAlDato.html",
    "href": "projects/DelFuegoAlDato.html",
    "title": "Del Fuego Al Dato",
    "section": "",
    "text": "Link (Spanish): https://olafmeneses.shinyapps.io/delfuegoaldato Post under construction…"
  },
  {
    "objectID": "projects/transitaire.html",
    "href": "projects/transitaire.html",
    "title": "VLC TrànsitAire",
    "section": "",
    "text": "Link (Spanish): https://olafmeneses.shinyapps.io/transitaire Post under construction…"
  },
  {
    "objectID": "projects/ruzafapp.html",
    "href": "projects/ruzafapp.html",
    "title": "Ruzafapp",
    "section": "",
    "text": "Link (English): https://wooflaf.shinyapps.io/ruzafapp Link (Spanish): https://olafmeneses.shinyapps.io/ruzafapp Post under construction…"
  }
]